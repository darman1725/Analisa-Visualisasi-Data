{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyspark-demo.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/darman1725/Analisa-Visualisasi-Data/blob/main/pyspark_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Langkah Praktikum**"
      ],
      "metadata": {
        "id": "tUOQFqLU7UQE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada pertemuan kali ini akan dilakukan visualisasi data pada big data. Untuk memudahkan \n",
        "praktikum akan menggunakan layanan Google Colab. "
      ],
      "metadata": {
        "id": "3BZmXAE27bop"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pengaturan Google Cola**b\n",
        "\n",
        "Untuk menggunakan layanan Google Colab dapat diakses pada halaman \n",
        "https://colab.research.google.com/ . Silahkan gunakan akun Gmail untuk masuk ke \n",
        "layanan tersebut. Pilih tombol New Notebook dan ubah nama menjadi pyspark\u0002demo.ipynb. Notebook di sini adalah platform jupyter notebook yang dihosting di layanan \n",
        "Google Colab."
      ],
      "metadata": {
        "id": "vd3OhGQL7dBL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pengaturan PySpark di Colab**\n",
        "\n",
        "Spark ditulis menggunakan bahasa pemrogrraman Scala dan membutuhkan Java Virtual \n",
        "Machine (JVM) untuk menjalankannya. Sebagai langkah pertama, lakukan instalasi Java \n",
        "dengan menuliskan perintah di bawah ini."
      ],
      "metadata": {
        "id": "taHJ_4AU7heq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3emxay6lyxkL"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Untuk instalasi Apache Spark, unduh berkas menggunakan perintah wget kemudian \n",
        "ekstrak dengan perintah tar. Silahkan salin perintah berikut untuk melakukan instalasi."
      ],
      "metadata": {
        "id": "ofBGZ5e67sR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.1-bin-hadoop3.2.tgz"
      ],
      "metadata": {
        "id": "xyeKrQfDy2Gj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sebagai Langkah lanjutan, dibutuhkan pengaturan terkait Java dan Spark Home. Untuk \n",
        "melakukannya dapat memanfaatkan script pyton. Silahkan masukkan kode berikut ke \n",
        "dalam notebook."
      ],
      "metadata": {
        "id": "fnU37-mj7u8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\"\n"
      ],
      "metadata": {
        "id": "8EW6BiB6y2np"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Konfigurasi PySpark**\n",
        "\n",
        "Konfigurasi PySpark dapat dilakukan dengan menginstall library findspark yang digunakan \n",
        "untuk mencari lokasi Spark yang terinstall pada sistem. Proses instalasi dapat \n",
        "memanfaatkan perintah pip, silahkan perhatikan perintah di bawah ini."
      ],
      "metadata": {
        "id": "3Fx4Poq97zG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "TCL8jHOwy4UT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setelah proses instalasi berhasil, lakukan import library dan inisialisasi findspark. Silahkan \n",
        "salin kode berikut ke dalam notebook."
      ],
      "metadata": {
        "id": "s7dtb0fM73Mv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "OMPmS04Ry5lZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Koneksi ke dalam spark dapat dilakukan memanfaatkan SparkSession. Salin kode berikut, \n",
        "dimana spark menggunakan port 4050."
      ],
      "metadata": {
        "id": "Mb6ewfAQ75vR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder\\\n",
        " .master(\"local\")\\\n",
        " .appName(\"Colab\")\\\n",
        " .config('spark.ui.port', '4050')\\\n",
        " .getOrCreate()"
      ],
      "metadata": {
        "id": "bzkQ3bywy6_a"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Memasukkan data ke dalam PySpark**\n",
        "\n",
        "Spark mempunyai beberapa modul untuk membaca data dengan format yang berbeda. \n",
        "Spark secara otomatis akan menentukan tiap tipe data untuk setiap kolom. Data yang \n",
        "akan digunakan sebagai dataset dapat diunduh menggunakan perintah wget. Silahkan \n",
        "perhatikan perintah berikut.\n"
      ],
      "metadata": {
        "id": "8hJAFImo798C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --continue https://raw.githubusercontent.com/dhanifudin/pyspark-demo/main/sample_books.json -O /tmp/sample_books.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gvg0qB_Fy_EL",
        "outputId": "54af4198-3262-47b0-b728-d1e81e002ae9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-09 15:12:50--  https://raw.githubusercontent.com/dhanifudin/pyspark-demo/main/sample_books.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data yang telah diunduh dapat dibaca dengan menggunakan kode berikut. Silahkan salin \n",
        "kode berikut ke dalam notebook."
      ],
      "metadata": {
        "id": "wbRr4zZd8DQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read JSON file into dataframe\n",
        "df = spark.read.json(\"/tmp/sample_books.json\")\n"
      ],
      "metadata": {
        "id": "PJWwyiPFy_yq"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analisa data menggunakan PySpark**\n",
        "\n",
        "Sebelum dapat menganalisa dataset, perlu mengetahui schema data yang akan diolah. \n",
        "Schema dapat diketahui dengan menggunakan kode berikut. Kode ini memanfaatkan \n",
        "dataframe."
      ],
      "metadata": {
        "id": "sEeR1BzQ8J-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZO3-WJUdzLtr",
        "outputId": "5596b683-2794-4ff4-b8b0-b883febb292f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- author: string (nullable = true)\n",
            " |-- edition: string (nullable = true)\n",
            " |-- price: double (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- year_written: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Menampilkan data**\n",
        "\n",
        "Dataset dapat ditampilkan dengan perintah show dari dataframe. Perintah show memiliki \n",
        "parameter berupa jumlah record yang ditampilkan serta opsi truncate. Silahkan salin kode \n",
        "beriikut ke dalam notebook."
      ],
      "metadata": {
        "id": "CKdVj3V88OQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(4,False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNYm6knazVx8",
        "outputId": "ca0481c5-aed1-4b8c-fbb4-90b4bc2da656"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+--------------+-----+----------------+------------+\n",
            "|author         |edition       |price|title           |year_written|\n",
            "+---------------+--------------+-----+----------------+------------+\n",
            "|Austen, Jane   |Penguin       |18.2 |Northanger Abbey|1814        |\n",
            "|Tolstoy, Leo   |Penguin       |12.7 |War and Peace   |1865        |\n",
            "|Tolstoy, Leo   |Penguin       |13.5 |Anna Karenina   |1875        |\n",
            "|Woolf, Virginia|Harcourt Brace|25.0 |Mrs. Dalloway   |1925        |\n",
            "+---------------+--------------+-----+----------------+------------+\n",
            "only showing top 4 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Menghitung jumlah dataset**\n",
        "\n",
        "Dataset dapat dihitung menggunakan fungsi count, silahkan salin kode berikut ke dalam \n",
        "untuk mengetahui jumlah dataset yang dimiliki."
      ],
      "metadata": {
        "id": "6fsAyp4T8Rpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMbYeMW6zY4T",
        "outputId": "52d49de3-808f-4194-f24d-569273f457ba"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Menampilkan kolom yang diinginkan**\n",
        "\n",
        "Dataset dapat dipilih untuk menampilkan data dengan kolom tertentu dengan fungsi \n",
        "select. Untuk menampilkan hanya kolom title, price dan year_written, silahkan salin kode \n",
        "berikut ke dalam colab."
      ],
      "metadata": {
        "id": "etKq5gmH8erq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(\"title\", \"price\", \"year_written\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4tBc8KKzd26",
        "outputId": "2f73ae4a-9098-47e2-859a-a14aa9dcbde0"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+-----+------------+\n",
            "|           title|price|year_written|\n",
            "+----------------+-----+------------+\n",
            "|Northanger Abbey| 18.2|        1814|\n",
            "|   War and Peace| 12.7|        1865|\n",
            "|   Anna Karenina| 13.5|        1875|\n",
            "|   Mrs. Dalloway| 25.0|        1925|\n",
            "|       The Hours|12.35|        1999|\n",
            "+----------------+-----+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Me-filter dataset**\n",
        "\n",
        "PySpark dapat juga melakukan filter suatu dataset berdasarkan kondisi yang dibutuhkan. \n",
        "Sebagai contoh: dataset yang ingin ditampilkan adalah buku yang ditulis setelah tahun \n",
        "1950 dan harganya lebih dari $10. Filter dapat dilakukan dengan menuliskan kode berikut."
      ],
      "metadata": {
        "id": "CMjYDw9q8jLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered = df.filter(\"year_written > 1950 AND price > 10 AND title IS NOT NULL\")\n",
        "df_filtered.select(\"title\", \"price\", \"year_written\").show(50,False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kq2nf0N6zd9t",
        "outputId": "1aa045e3-8d73-46c1-f1d9-9158e87c3f73"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------+-----+------------+\n",
            "|title                        |price|year_written|\n",
            "+-----------------------------+-----+------------+\n",
            "|The Hours                    |12.35|1999        |\n",
            "|Harry Potter                 |19.95|2000        |\n",
            "|One Hundred Years of Solitude|14.0 |1967        |\n",
            "+-----------------------------+-----+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Penggunaan PySpark SQL functions**\n",
        "\n",
        "PySpark mempunyai fungsi SQL lainnya, misalnya max, aggregate function (groupBy, sum, \n",
        "count dll). Contoh: menampilkan data buku paling mahal, dapat menggunakan fungsi \n",
        "max."
      ],
      "metadata": {
        "id": "vLCP6DfS8rMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import max\n",
        "\n",
        "# Find the costliest book\n",
        "maxValue = df_filtered.agg(max(\"price\")).collect()[0][0]\n",
        "print(\"maxValue: \",maxValue)\n",
        "\n",
        "df_filtered.select(\"title\",\"price\").filter(df.price == maxValue).show(20, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VL18Nq41zjmC",
        "outputId": "98f686d3-3fb9-4a02-ac10-3b7caf78be82"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maxValue:  19.95\n",
            "+------------+-----+\n",
            "|title       |price|\n",
            "+------------+-----+\n",
            "|Harry Potter|19.95|\n",
            "+------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TUGAS !"
      ],
      "metadata": {
        "id": "sVdncySrz0La"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCLj1a-Qzzhj",
        "outputId": "fb8cb04b-a956-4f5c-aa42-37860d1cbda3"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----------------+-----+--------------------+------------+\n",
            "|              author|          edition|price|               title|year_written|\n",
            "+--------------------+-----------------+-----+--------------------+------------+\n",
            "|        Austen, Jane|          Penguin| 18.2|    Northanger Abbey|        1814|\n",
            "|        Tolstoy, Leo|          Penguin| 12.7|       War and Peace|        1865|\n",
            "|        Tolstoy, Leo|          Penguin| 13.5|       Anna Karenina|        1875|\n",
            "|     Woolf, Virginia|   Harcourt Brace| 25.0|       Mrs. Dalloway|        1925|\n",
            "|Cunnningham, Michael|   Harcourt Brace|12.35|           The Hours|        1999|\n",
            "|         Twain, Mark|          Penguin| 5.76|    Huckleberry Finn|        1865|\n",
            "|    Dickens, Charles|     Random House| 5.75|         Bleak House|        1870|\n",
            "|         Twain, Mark|     Random House| 7.75|          Tom Sawyer|        1862|\n",
            "|     Woolf, Virginia|          Penguin| 29.0| A Room of One's Own|        1922|\n",
            "|       Rowling, J.K.|   Harcourt Brace|19.95|        Harry Potter|        2000|\n",
            "|             Marquez|Harper  Perennial| 14.0|One Hundred Years...|        1967|\n",
            "|         Shakespeare| Signet  Classics| 7.95|Hamlet, Prince of...|        1603|\n",
            "|       Tolkien, J.R.|          Penguin|27.45|   Lord of the Rings|        1937|\n",
            "+--------------------+-----------------+-----+--------------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Tampilkan data buku dengan harga paling murah!\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Gv8iw6T30Eyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import min\n",
        "\n",
        "# Find the cheapest price\n",
        "\n",
        "minValue = df.agg(min(\"price\")).collect()[0][0]\n",
        "print(\"minValue: \",minValue)\n",
        "\n",
        "df.select(\"author\", \"edition\", \"price\", \"title\", \"year_written\").filter(df.price == minValue).show(20, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODve6ZxH0LB9",
        "outputId": "1fde16f2-f041-48d7-bf9b-20937a36b8ef"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "minValue:  5.75\n",
            "+----------------+------------+-----+-----------+------------+\n",
            "|author          |edition     |price|title      |year_written|\n",
            "+----------------+------------+-----+-----------+------------+\n",
            "|Dickens, Charles|Random House|5.75 |Bleak House|1870        |\n",
            "+----------------+------------+-----+-----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Tampilkan jumlah terbit buku dikategorikan setiap tahun ditulis!\n",
        "\n"
      ],
      "metadata": {
        "id": "pUYVPu0O08Uz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.sql.functions as f\n",
        "from pyspark.sql.functions import desc\n",
        "\n",
        "df.groupBy(\"year_written\").count().select(\"year_written\", f.col(\"count\").\n",
        "alias (\"jml_terbit_setiap_tahun\")).sort(desc(\"year_written\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HH4joi7z0_YJ",
        "outputId": "92bac575-ac18-48f5-d59f-468145ddeb81"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------------------+\n",
            "|year_written|jml_terbit_setiap_tahun|\n",
            "+------------+-----------------------+\n",
            "|        2000|                      1|\n",
            "|        1999|                      1|\n",
            "|        1967|                      1|\n",
            "|        1937|                      1|\n",
            "|        1925|                      1|\n",
            "|        1922|                      1|\n",
            "|        1875|                      1|\n",
            "|        1870|                      1|\n",
            "|        1865|                      2|\n",
            "|        1862|                      1|\n",
            "|        1814|                      1|\n",
            "|        1603|                      1|\n",
            "+------------+-----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Tampilkan data buku termahal tiap tahun penulisannya!"
      ],
      "metadata": {
        "id": "5g5wCOhc1OtS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.sql.functions as f\n",
        "from pyspark.sql.functions import desc\n",
        "\n",
        "df.groupBy(\"year_written\").agg({\"Price\" : \"max\"}).sort(desc(\"year_written\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8yaKsxk1SWT",
        "outputId": "d9b3f662-369d-46a2-efc0-a764a8d44f90"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----------+\n",
            "|year_written|max(Price)|\n",
            "+------------+----------+\n",
            "|        2000|     19.95|\n",
            "|        1999|     12.35|\n",
            "|        1967|      14.0|\n",
            "|        1937|     27.45|\n",
            "|        1925|      25.0|\n",
            "|        1922|      29.0|\n",
            "|        1875|      13.5|\n",
            "|        1870|      5.75|\n",
            "|        1865|      12.7|\n",
            "|        1862|      7.75|\n",
            "|        1814|      18.2|\n",
            "|        1603|      7.95|\n",
            "+------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Tampilkan data buku termurah tiap tahun penulisannya!"
      ],
      "metadata": {
        "id": "WH2zzexk1XuT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.sql.functions as f\n",
        "from pyspark.sql.functions import desc\n",
        "\n",
        "df.groupBy(\"year_written\").agg({\"Price\" : \"min\"}).sort(desc(\"year_written\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fd9SQhC1dDa",
        "outputId": "f3a53caf-08e6-4a3b-b123-6491e8f63f52"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----------+\n",
            "|year_written|min(Price)|\n",
            "+------------+----------+\n",
            "|        2000|     19.95|\n",
            "|        1999|     12.35|\n",
            "|        1967|      14.0|\n",
            "|        1937|     27.45|\n",
            "|        1925|      25.0|\n",
            "|        1922|      29.0|\n",
            "|        1875|      13.5|\n",
            "|        1870|      5.75|\n",
            "|        1865|      5.76|\n",
            "|        1862|      7.75|\n",
            "|        1814|      18.2|\n",
            "|        1603|      7.95|\n",
            "+------------+----------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}